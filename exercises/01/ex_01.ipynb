{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A simple MATLAB function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# identity matrix\n",
    "A = np.eye(5, dtype=int)\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear regression with one variable\n",
    "## 2.1 Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and analyze data\n",
    "data_file_1 = Path(os.path.abspath('')).absolute() / \"data\" / \"ex1data1.txt\"\n",
    "data_set_1 = pd.read_csv(data_file_1, header=None, names=[\"Population\", \"Profit\"])\n",
    "# print(data)\n",
    "# print(data.head())\n",
    "# print(data.describe())\n",
    "\n",
    "# make plot of dataframe. by default, matplotlib backend is used.\n",
    "data_set_1.plot(kind='scatter', x='Population', y='Profit')\n",
    "plt.show()\n",
    "\n",
    "# extract data\n",
    "x = np.matrix(data_set_1.iloc[:, :1])\n",
    "y = np.matrix(data_set_1.iloc[:, 1:])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Gradient Descent\n",
    "### 2.2.1 Update Equations\n",
    "### 2.2.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of training examples\n",
    "m = len(x)\n",
    "# insert np.ones(m) to column 0\n",
    "X = np.insert(x, 0, np.ones(m), axis=1)\n",
    "print(X)\n",
    "# init theta with 0s\n",
    "theta = np.matrix(np.zeros((2,1)))\n",
    "print(theta)\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "X.shape, y.shape, theta.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Computing the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute cost\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    sum = 0\n",
    "    for i in range(0, m):\n",
    "        diff = np.matrix(X[i]) * theta - y[i]\n",
    "        sum += diff.item() ** 2\n",
    "    return 1 / (2 * m) * sum\n",
    "\n",
    "print(compute_cost(X, y, theta))\n",
    "# init theta with [[-1],[2]]\n",
    "print(compute_cost(X, y, np.matrix([[-1],[2]])))\n",
    "\n",
    "# simpler vectorized method\n",
    "def vectorized_compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = X * theta\n",
    "    diff = h - y\n",
    "    res = 1 / (2 * m) * np.sum(np.square(diff)) \n",
    "    return res\n",
    "\n",
    "print(vectorized_compute_cost(X, y, theta))\n",
    "# init theta with [[-1],[2]]\n",
    "print(vectorized_compute_cost(X, y, np.matrix([[-1],[2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorized gradient descent method\n",
    "def gradientDescent(X, y, theta, alpha, iterations):\n",
    "    new_theta = theta.copy()\n",
    "    costs = []\n",
    "    for it in range(iterations):\n",
    "        sum = 0\n",
    "        m = len(X)\n",
    "        for i in range(m):\n",
    "            sum += (new_theta.T * X[i].T - y[i]).item() * X[i].T\n",
    "        new_theta -= alpha * 1 / (2 * m) * sum\n",
    "        new_cost = vectorized_compute_cost(X, y, new_theta)\n",
    "        costs.append(new_cost)\n",
    "    return new_theta, costs\n",
    "\n",
    "learned_theta, costs = gradientDescent(X, y, theta, alpha, iterations)\n",
    "\n",
    "print(learned_theta)\n",
    "print(costs[-5 : -1])\n",
    "\n",
    "# predict values for population sizes of 35,000 and 70,000\n",
    "prediction1 = (np.matrix([1, 3.5]) * learned_theta).item()\n",
    "prediction2 = (np.matrix([1, 7]) * learned_theta).item()\n",
    "print(\"prediction 1: population 3.5, profit {}\".format(prediction1))\n",
    "print(\"prediction 1: population 7, profit {}\".format(prediction2))\n",
    "\n",
    "# visualize result\n",
    "x_vector = np.linspace(data_set_1.Population.min(), data_set_1.Population.max(), 100)\n",
    "x_constructed = np.insert(np.matrix(x_vector), 0, np.ones(100), axis=0)\n",
    "y_constructed = learned_theta.T * x_constructed\n",
    "y_vector = np.array(y_constructed).flatten()\n",
    "print(x_vector)\n",
    "print(y_vector)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8,16))\n",
    "ax1.plot(x, y, \"o\", label=\"training data\")\n",
    "ax1.plot(x_vector, y_vector, \"-\", label=\"prediction\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Predicted Profit\")\n",
    "ax1.set_xlabel(\"Population\")\n",
    "ax1.set_ylabel(\"Profit\")\n",
    "ax2.plot(range(1, iterations + 1), costs, \"-\")\n",
    "ax2.set_title(\"Cost\")\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Debugging\n",
    "## 2.4 Visualizing J(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta1_vector = np.linspace(-10, 10, 100)\n",
    "theta2_vector = np.linspace(-1, 4, 100)\n",
    "cost_vector = np.zeros((len(theta2_vector), len(theta1_vector)))\n",
    "\n",
    "# create Z grid for the coordinate system\n",
    "for i in range(len(theta2_vector)):\n",
    "    for j in range(len(theta1_vector)):\n",
    "        cost_vector[i][j] = vectorized_compute_cost(X, y, np.matrix([[theta1_vector[j]],[theta2_vector[i]]]))\n",
    "\n",
    "# transfer X, Y vector to grid for the coordinate system\n",
    "theta1_vector_mesh, theta2_vector_mesh = np.meshgrid(theta1_vector, theta2_vector)\n",
    "\n",
    "print(theta1_vector_mesh)\n",
    "print(theta2_vector_mesh)\n",
    "print(cost_vector)\n",
    "\n",
    "# 3D surface figure\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.gca(projection=\"3d\")\n",
    "ax1.set_xlabel(\"Theta1\")\n",
    "ax1.set_ylabel(\"Theta2\")\n",
    "ax1.set_zlabel(\"Cost\")\n",
    "surf = ax1.plot_surface(theta1_vector_mesh, theta2_vector_mesh, cost_vector, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "cbar1 = fig1.colorbar(surf)\n",
    "cbar1.set_label(\"Cost\")\n",
    "\n",
    "# contour figure\n",
    "fig2, ax2 = plt.subplots()\n",
    "contour = ax2.contour(theta1_vector_mesh, theta2_vector_mesh, cost_vector, levels=100, cmap=cm.coolwarm)\n",
    "ax2.set_xlabel(\"Theta1\")\n",
    "ax2.set_ylabel(\"Theta2\")\n",
    "cbar2 = fig2.colorbar(contour)\n",
    "cbar2.set_label(\"Cost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear regression with multiple variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_file_2 = Path(os.path.abspath('')).absolute() / \"data\" / \"ex1data2.txt\"\n",
    "data_set_2 = pd.read_csv(data_file_2, header=None, names=[\"Size\", \"Bedrooms\", \"Price\"])\n",
    "x = np.matrix(data_set_2.iloc[:, :2])\n",
    "y = np.matrix(data_set_2.iloc[:, 2:])\n",
    "print(data_set_2.head())\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature normalization (standardization)\n",
    "def featureNormalize(x):\n",
    "    mu = np.mean(x, axis=0)\n",
    "    sigma = np.std(x, axis=0)\n",
    "    # get normalized_x from element-wise operations\n",
    "    normalized_x = (x - mu) / sigma\n",
    "    # check if res_mu == 0 and res_variance = 1\n",
    "    # res_mu = np.mean(normalized_x, axis=0)\n",
    "    # res_variance = np.var(normalized_x, axis=0)\n",
    "    # print(res_mu)\n",
    "    # print(res_variance)\n",
    "    return normalized_x, mu, sigma\n",
    "\n",
    "normalized_x, mu, sigma = featureNormalize(x)\n",
    "print(normalized_x)\n",
    "print(mu)\n",
    "print(sigma)\n",
    "\n",
    "# number of training examples\n",
    "m = len(normalized_x)\n",
    "# insert np.ones(m) to column 0\n",
    "X = np.insert(normalized_x, 0, np.ones(m), axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "iterations = 400\n",
    "theta = np.matrix(np.zeros((3, 1)))\n",
    "\n",
    "learned_theta, costs = gradientDescent(X, y, theta, alpha, iterations)\n",
    "print(learned_theta)\n",
    "print(costs[-5 : -1])\n",
    "\n",
    "# show if cost converage\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, iterations + 1), costs, \"-\")\n",
    "plt.show()\n",
    "\n",
    "# normalize test data input\n",
    "def normalize_test_x(x, mu, sigma):\n",
    "    normalized_test_x = (x - mu) / sigma\n",
    "    return normalized_test_x\n",
    "\n",
    "# normalize input before prediction\n",
    "normalized_test_x = normalize_test_x(np.matrix([1650, 3]), mu, sigma)\n",
    "# insert 1 to normalized_test_x\n",
    "test_x = np.insert(normalized_test_x, 0, 1, 1)\n",
    "multi_prediction = (test_x * learned_theta).item()\n",
    "\n",
    "print(test_x)\n",
    "print(multi_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}