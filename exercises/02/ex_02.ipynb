{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('ml_course': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "9e6836700e96a853fe4b0f9f6772835270a845f6671132c1dde5eaf8914ce878"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. Logistic Regression\n",
    "* need to fix python float calculation accuracy (nomalize traing data?)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_file_1 = Path(os.path.abspath(\"\")) / \"data\" / \"ex2data1.txt\"\n",
    "data_set_1 = pd.read_csv(data_file_1, header=None, names=[\"Score_1\", \"Score_2\", \"Admitted\"])\n",
    "# print(data_set_1)\n",
    "# print(data_set_1.head())\n",
    "# print(data_set_1.describe())\n",
    "\n",
    "x = np.matrix(data_set_1.iloc[:, 0:2])\n",
    "y = np.matrix(data_set_1.iloc[:, 2:])\n",
    "m, n = x.shape\n",
    "print(m, n)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "## 1.1 Visualizing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init empty array with dimensions\n",
    "admitted_list = np.empty((0, 3))\n",
    "non_admitted_list = np.empty((0, 3))\n",
    "\n",
    "for record in np.array(data_set_1):\n",
    "    if record[2] == 1:\n",
    "        admitted_list = np.append(admitted_list, [record], axis=0)\n",
    "    else:\n",
    "        non_admitted_list = np.append(non_admitted_list, [record], axis=0)\n",
    "\n",
    "# simple way to init\n",
    "# admitted_list = np.array([record for record in np.array(data_set_1) if record[2] == 1])\n",
    "# non_admitted_list = np.array([record for record in np.array(data_set_1) if record[2] == 0])\n",
    "\n",
    "# print(admitted_list)\n",
    "# print(not_admitted_list)\n",
    "\n",
    "plt.plot(admitted_list[:, 0], admitted_list[:, 1], 'go', label=\"Admitted\")\n",
    "plt.plot(non_admitted_list[:, 0], non_admitted_list[:, 1], 'ro', label=\"Non-admitted\")\n",
    "plt.xlabel(\"Score_1\")\n",
    "plt.ylabel(\"Score_2\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "## 1.2 Implementation\n",
    "### 1.2.1 Sigmoid function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # print(\"### sigmoid start ###\")\n",
    "    # print(z)\n",
    "    # print(np.exp(-z))\n",
    "    # print(1 + np.exp(-z))\n",
    "    # print(1 / (1 + np.exp(-z)))\n",
    "    # print(\"### sigmoid end ###\")\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# draw sigmoid\n",
    "sigmoid_x = np.linspace(-10, 10)\n",
    "sigmoid_y = sigmoid(sigmoid_x)\n",
    "plt.plot(sigmoid_x, sigmoid_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.insert(x, 0, np.zeros(m), axis=1)\n",
    "# print(X)\n",
    "init_theta = np.matrix(np.zeros((n + 1, 1)))\n",
    "# print(init_theta)\n",
    "\n",
    "def cost(theta, X, y):\n",
    "    h = sigmoid(X * theta)\n",
    "    m = X.shape[0]\n",
    "    # print(X)\n",
    "    # print(theta)\n",
    "    # print(X * theta)\n",
    "    # print(h)\n",
    "    j = 1 / m * (-y.T * np.log(h) - (1 - y).T * np.log(1 - h))\n",
    "    # print(-y.T)\n",
    "    # print(np.log(h))\n",
    "    # print(-y.T * np.log(h))\n",
    "    # print((1 - y).T)\n",
    "    # print(1 - h)\n",
    "    # print(np.log(1 - h))\n",
    "    # print((1 - y).T * np.log(1 - h))\n",
    "    return j\n",
    "\n",
    "def gradient(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    gradient = 1 / m * X.T * (sigmoid(X * theta) - y)\n",
    "    return gradient\n",
    "\n",
    "# cost and gradient when theta = [[0], [0], [0]]\n",
    "print(cost(init_theta, X, y))\n",
    "print(gradient(init_theta, X, y))\n",
    "\n",
    "# cost and gradient when theta = [[-24], [0.2], [0.2]]\n",
    "# * loat caculation error found in this case\n",
    "print(cost(np.matrix([[-24], [0.2], [0.2]]), X, y))\n",
    "print(gradient(np.matrix([[-24], [0.2], [0.2]]), X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ]
}